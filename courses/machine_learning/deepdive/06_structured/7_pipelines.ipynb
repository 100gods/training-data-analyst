{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubeflow pipelines\n",
    "\n",
    "This notebook goes through the steps of using Kubeflow pipelines using the Python3 interpreter (command-line) to preprocess, train, tune and deploy the babyweight model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start Hosted Pipelines\n",
    "\n",
    "Create Hosted Kubeflow Pipelines Instance\n",
    "\n",
    "* Navigate to https://console.cloud.google.com/marketplace/details/google-cloud-ai-platform/kubeflow-pipelines\n",
    "* Make sure your GCP project is selected in the dropdown at the top.\n",
    "* Click CONFIGURE\n",
    "* Change the App Instance Name to “kfpdemo”\n",
    "* Click on the Create Cluster button and wait 2-3 minutes for cluster to get created.\n",
    "* Click Deploy\n",
    "* Navigate to https://console.cloud.google.com/ai-platform/pipelines/clusters\n",
    "* Click on the HOSTED PIPELINES DASHBOARD LINK for kfpdemo on the cluster that you just started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Launch AI Platform notebook\n",
    "\n",
    "Create Notebooks instance\n",
    "* Navigate to https://console.cloud.google.com/ai-platform/notebooks/instances\n",
    "* Click on +New Instance and create a TensorFlow 2.x notebook\n",
    "* Name the instance kfpdemo\n",
    "* Click Customize \n",
    "  * In Machine Configuration, change it to n1-standard-2\n",
    "  * In Permissions, set the notebook to be single-user and provide your GCP login email\n",
    "  * Click Create\n",
    "* Click on the URL for Open JupyterLab\n",
    "* Open a Terminal\n",
    "* Type:\n",
    "    ```git clone https://github.com/GoogleCloudPlatform/training-data-analyst```\n",
    "* On the left-hand side menu, navigate to this notebook (training-data-analyst/courses/machine_learning/deepdive/06_structured/7_pipelines.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: tensorflow-probability 0.9.0 has requirement cloudpickle>=1.2.2, but you'll have cloudpickle 1.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[33m  WARNING: The script pyjwt is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tabulate is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts dsl-compile and kfp are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet kfp python-dateutil --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to *restart the kernel* to pick up new packages (look for button in the ribbon of icons above this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Connect to the Hosted Pipelines\n",
    "\n",
    "Visit https://console.cloud.google.com/ai-platform/pipelines/clusters\n",
    "and get the hostname for your cluster.  You can get it by clicking on the Settings icon.\n",
    "Alternately, click on the Open Pipelines Dashboard link and look at the URL.\n",
    "Change the settings in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE\n",
    "PIPELINES_HOST='447cdd24f70c9541-dot-us-central1.notebooks.googleusercontent.com'\n",
    "PROJECT='ai-analytics-solutions'\n",
    "BUCKET='ai-analytics-solutions-kfpdemo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "client = kfp.Client(host=PIPELINES_HOST)\n",
    "#client.list_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Upload and execute pipeline\n",
    "\n",
    "Upload to the Kubeflow pipeline cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"http://447cdd24f70c9541-dot-us-central1.notebooks.googleusercontent.com/#/experiments/details/305492c2-1ff3-46e4-b9bf-3c63790eb46a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://447cdd24f70c9541-dot-us-central1.notebooks.googleusercontent.com/#/runs/details/d0dfe4cd-dc24-4c9b-b0d2-09c56b1d9641\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pipelines import mlp_babyweight\n",
    "\n",
    "pipeline = client.create_run_from_pipeline_func(mlp_babyweight.train_and_deploy, \n",
    "                                                arguments={'project': PROJECT, 'bucket': BUCKET})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
