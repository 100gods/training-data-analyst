{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxWsQffj1ysi"
   },
   "source": [
    "# LAB 02:   Advanced Feature Engineering in BQML\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "1. Apply ML.FEATURE_CROSS to categorical features\n",
    "2. Create a Euclidan feature column\n",
    "3. Feature cross coordinate features\n",
    "4. Apply the BUCKETIZE function\n",
    "5. Apply the TRANSFORM clause and L2 Regularization\n",
    "6. Evaluate the model using ML.PREDICT\n",
    "\n",
    "\n",
    "## Introduction \n",
    "In this lab, we continue to utilize feature engineering to improve the prediction of the fare amount for a taxi ride in New York City by reducing the RMSE.\n",
    "\n",
    "In this Notebook, we perform a feature cross using BigQuery's ML.FEATURE_CROSS, derive coordinate features, feature cross coordinate features, clean up the code, apply the BUCKETIZE function, the TRANSFORM clause, L2 Regularization, and evaluate model performance throughout the process.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the notebook where you will complete the notebook cell's code before running. Refer to the [solution](courses/machine_learning/deepdive2/feature_engineering/solutions/2_bqml_adv_feat_eng.ipynb) for reference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbSRbuJ-fYtK"
   },
   "source": [
    "### Model 4:  Apply the ML.FEATURE_CROSS clause to categorical features\n",
    "\n",
    "BigQuery ML now has ML.FEATURE_CROSS, a pre-processing clause that performs a feature cross.  \n",
    "\n",
    "* ML.FEATURE_CROSS generates a [STRUCT](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#struct-type) feature with all combinations of crossed categorical features, except for 1-degree items (the original features) and self-crossing items.  \n",
    "\n",
    "* Syntax:  ML.FEATURE_CROSS(STRUCT(features), degree)\n",
    "\n",
    "* The feature parameter is a categorical features separated by comma to be crossed. The maximum number of input features is 10. An unnamed feature is not allowed in features. Duplicates are not allowed in features.\n",
    "\n",
    "* Degree(optional): The highest degree of all combinations. Degree should be in the range of [1, 4]. Default to 2.\n",
    "\n",
    "Output: The function outputs a STRUCT of all combinations except for 1-degree items (the original features) and self-crossing items, with field names as concatenation of original feature names and values as the concatenation of the column string values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zZI0X6s1ysl"
   },
   "source": [
    "We continue with feature engineering began in Lab 01.  Here, we examine the components of ML.Feature_Cross.  \n",
    "\n",
    "Note that the ML.FEATURE_CROSS statement contains errors, please correct the statement before continuing or you will get errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfKmfGqw1ysq",
    "outputId": "adb978c5-90cb-4ee2-eaad-ad8060276d16"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL feat_eng.model_4\n",
    "OPTIONS\n",
    "  (model_type='linear_reg',\n",
    "    input_label_cols=['fare_amount'])  \n",
    "AS\n",
    "SELECT\n",
    "  fare_amount,\n",
    "  passengers,\n",
    "  #pickup_datetime,\n",
    "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
    "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "  #CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING), \n",
    "        #CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
    " \n",
    "  #TODO 1: Correct the ML.FEATURE_CROSS statement\n",
    "  ML.FEATURE_CROSS(CAST(STRUCT(CAST(DAYOFWEEK FROM pickup_datetime) AS STRING) AS dayofweek,\n",
    "  STRUCT(CAST(HOUR FROM pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "  \n",
    "pickuplon,\n",
    "  pickuplat,\n",
    "  dropofflon,\n",
    "  dropofflat\n",
    "  \n",
    "FROM `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6tpoYhcIgs4"
   },
   "source": [
    "Next, two distinct SQL statements show the TRAINING and EVALUATION metrics of model_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymzRp28Q1ys1"
   },
   "source": [
    "### Sliding down the slope toward a loss minimum (reduced taxi fare)!\n",
    "* Our fourth model above gives us an RMSE of 9.65 for estimating fares. Recall our heuristic benchmark was 8.29. This may be the result of feature crossing.  Let's apply more feature engineering techniques to see if we can't get this loss metric lower!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NAPkAlEEg6C"
   },
   "source": [
    "### Model 5:  Feature cross coordinate features to create a Euclidean feature\n",
    "\n",
    "\n",
    "Pickup coordinate:\n",
    "*  pickup_longitude AS pickuplon\n",
    "*  pickup_latitude AS pickuplat\n",
    "\n",
    "Dropoff coordinate:\n",
    "*   #dropoff_longitude AS dropofflon\n",
    "*   #dropoff_latitude AS dropofflat\n",
    "\n",
    "**Coordinate Features**:\n",
    "* The pick-up and drop-off longitude and latitude data are crucial to predicting the fare amount as fare amounts in NYC taxis are largely determined by the distance traveled.  As such, we need to  teach the model the Euclidean distance between the pick-up and drop-off points.  \n",
    "\n",
    "* Recall that latitude and longitude allows us to specify any location on Earth using a set of coordinates.  In our training data set, we restricted our data points to only pickups and drop offs within NYC. New York city has an approximate longitude range of -74.05 to -73.75 and a latitude range of 40.63 to 40.85.\n",
    "\n",
    "* The dataset contains information regarding the pickup and drop off coordinates. However, there is no information regarding the distance between the pickup and drop off points. Therefore, we create a new feature that calculates the distance between each pair of pickup and drop off points. We can do this using the Euclidean Distance, which is the straight-line distance between any two coordinate points.\n",
    "\n",
    "* We need to convert those coordinates into a single column of a spatial data type.  We will use the ST_DISTANCE and the ST_GEOGPOINT functions.  \n",
    "\n",
    "* ST_DISTANCE:  ST_DISTANCE(geography_1, geography_2).  Returns the shortest distance in meters between two non-empty GEOGRAPHYs (e.g. between two spatial objects).\n",
    "\n",
    "* ST_GEOGPOINT:  ST_GEOGPOINT(longitude, latitude).  Creates a GEOGRAPHY with a single point. ST_GEOGPOINT creates a point from the specified FLOAT64 longitude and latitude parameters and returns that point in a GEOGRAPHY value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCYniJnejNz0"
   },
   "source": [
    "Next we convert the feature coordinates into a single column of a spatial data type. Use the The ST_Distance and the ST.GeogPoint functions.\n",
    "\n",
    "SAMPLE CODE:\n",
    "ST_Distance(ST_GeogPoint(value1,value2), ST_GeogPoint(value3, value4)) AS euclidean\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "P8mFocaKj9oA",
    "outputId": "77cb597a-b130-4b8a-a253-a2d72dc7da2e"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL\n",
    "  feat_eng.model_5 OPTIONS (model_type='linear_reg',\n",
    "    input_label_cols=['fare_amount']) AS\n",
    "SELECT\n",
    "  fare_amount,\n",
    "  passengers,\n",
    "  #pickup_datetime,\n",
    "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
    "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "  #CONCAT(CAST(EXTRACT(DAYOFWEEK FROM pickup_datetime) AS STRING),\n",
    "    #CAST(EXTRACT(HOUR FROM pickup_datetime) AS STRING)) AS hourofday,\n",
    "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS dayofweek,\n",
    "      CAST(EXTRACT(HOUR\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "  #pickuplon,\n",
    "  #pickuplat,\n",
    "  #dropofflon,\n",
    "  #dropofflat,\n",
    " \n",
    "  # TODO 2-- Your code here\n",
    "\n",
    "\n",
    "\n",
    "FROM\n",
    "  `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uy7eK6iXlYPu"
   },
   "source": [
    "Next, two distinct SQL statements show metrics for model_5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "9atctYyGlYP7",
    "outputId": "aa2e5513-4df8-4c0c-d08b-63690b567ecb"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "Lk42mvjzlYQE",
    "outputId": "e77d8fcc-ef55-40e5-aac1-5db287e0c4ea"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uUoQmADkmlnV"
   },
   "source": [
    "### Model 6:  Feature cross  pick-up and drop-off locations features\n",
    "\n",
    "In this section, we feature cross the pick-up and drop-off locations so that the model can learn pick-up-drop-off pairs that will require tolls.\n",
    "\n",
    "This step takes the geographic point corresponding to the pickup point and grids to a 0.1-degree-latitude/longitude grid (approximately 8km x 11km in New York—we should experiment with finer resolution grids as well). Then, it concatenates the pickup and dropoff grid points to learn “corrections” beyond the Euclidean distance associated with pairs of pickup and dropoff locations.\n",
    "\n",
    "Because the lat and lon by themselves don't have meaning, but only in conjunction, it may be useful to treat the fields as a pair instead of just using them as numeric values. However, lat and lon are continuous numbers, so we have to discretize them first. That's what SnapToGrid does. \n",
    "\n",
    "\n",
    "* ST_SNAPTOGRID:  ST_SNAPTOGRID(geography_expression, grid_size).  Returns the input GEOGRAPHY, where each vertex has been snapped to a longitude/latitude grid. The grid size is determined by the grid_size parameter which is given in degrees.\n",
    "\n",
    "**REMINDER**: The ST_GEOGPOINT creates a GEOGRAPHY with a single point. ST_GEOGPOINT creates a point from the specified FLOAT64 longitude and latitude parameters and returns that point in a GEOGRAPHY value.  The ST_Distance function returns the minimum distance between two spatial objectsa.  It also returns meters for geographies and SRID units for geometrics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9viHV3l1ytF"
   },
   "source": [
    "Modify the code to feature cross the pick-up and drop-off locations features.  Please correct the statement before continuing or you will get errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "7VjZawfZpQ7Y",
    "outputId": "10772712-3259-4f42-da8a-921a33c1e2bd"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL\n",
    "  feat_eng.model_6 OPTIONS (model_type='linear_reg',\n",
    "    input_label_cols=['fare_amount']) AS\n",
    "SELECT\n",
    "  fare_amount,\n",
    "  passengers,\n",
    "  #pickup_datetime,\n",
    "  #EXTRACT(DAYOFWEEK FROM pickup_datetime) AS dayofweek,\n",
    "  #EXTRACT(HOUR FROM pickup_datetime) AS hourofday,\n",
    "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS dayofweek,\n",
    "      CAST(EXTRACT(HOUR\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "  #pickuplon,\n",
    "  #pickuplat,\n",
    "  #dropofflon,\n",
    "  #dropofflat,\n",
    "  ST_Distance(ST_GeogPoint(pickuplon,\n",
    "      pickuplat),\n",
    "    ST_GeogPoint(dropofflon,\n",
    "      dropofflat)) AS euclidean,\n",
    "\n",
    "#TODO 3: Correct this statement. \n",
    "  CONCAT(ST_AsText(ST_GeogPoint(ST_SnapToGrid(dropofflon, pickuplon,\n",
    "          pickuplat, dropofflat),\n",
    "        0.01)), ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon,\n",
    "          dropofflat),\n",
    "        0.01))) AS pickup_and_dropoff\n",
    "FROM\n",
    "  `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvOfj_k1qijv"
   },
   "source": [
    "Next, we evaluate model_6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "G8rM09jLqij4",
    "outputId": "b24aa617-c46c-4cb9-f943-2e5a2d920945"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "CQUfOjPlqij8",
    "outputId": "b72347ac-3de0-49d4-b385-2955edf195ab"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1dW3JLHrP5Z"
   },
   "source": [
    "### Code Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4RL3f9K1ytN"
   },
   "source": [
    "#### Exercise:  Clean up the code to see where we are\n",
    "\n",
    "Remove all the commented statements in the SQL statement.  We should now have a total of five input features for our model.  \n",
    "1. fare_amount\n",
    "2. passengers\n",
    "3. day_hr\n",
    "4. euclidean\n",
    "5. pickup_and_dropoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UxZXY18rWG8",
    "outputId": "1901b6e0-78ea-4dbb-80a7-ae2da365b509"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL\n",
    "  feat_eng.model_6 OPTIONS (model_type='linear_reg',\n",
    "    input_label_cols=['fare_amount']) AS\n",
    "SELECT\n",
    "  fare_amount,\n",
    "  passengers,\n",
    "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS dayofweek,\n",
    "      CAST(EXTRACT(HOUR\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "  ST_Distance(ST_GeogPoint(pickuplon,\n",
    "      pickuplat),\n",
    "    ST_GeogPoint(dropofflon,\n",
    "      dropofflat)) AS euclidean,\n",
    "  CONCAT(ST_AsText(ST_SnapToGrid(ST_GeogPoint(pickuplon,\n",
    "          pickuplat),\n",
    "        0.01)), ST_AsText(ST_SnapToGrid(ST_GeogPoint(dropofflon,\n",
    "          dropofflat),\n",
    "        0.01))) AS pickup_and_dropoff\n",
    "FROM\n",
    "  `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSWHC_9Z1ytS"
   },
   "source": [
    "## BQML's Pre-processing functions:\n",
    "\n",
    "Here are some of the preprocessing functions in BigQuery ML:\n",
    "* ML.FEATURE_CROSS(STRUCT(features))    does a feature cross of all the combinations\n",
    "* ML.POLYNOMIAL_EXPAND(STRUCT(features), degree)    creates x, x<sup>2</sup>, x<sup>3</sup>, etc.\n",
    "* ML.BUCKETIZE(f, split_points)   where split_points is an array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENp6mUvB1ytT"
   },
   "source": [
    "### Model 7:  Apply the BUCKETIZE Function \n",
    "\n",
    "\n",
    "##### BUCKETIZE \n",
    "Bucketize is a pre-processing function that creates \"buckets\" (e.g bins) - e.g. it bucketizes a continuous numerical feature into a string feature with bucket names as the value.\n",
    "\n",
    "* ML.BUCKETIZE(feature, split_points)\n",
    "\n",
    "* feature: A numerical column.\n",
    "\n",
    "* split_points: Array of numerical points to split the continuous values in feature into buckets. With n split points (s1, s2 … sn), there will be n+1 buckets generated. \n",
    "\n",
    "* Output: The function outputs a STRING for each row, which is the bucket name. bucket_name is in the format of bin_<bucket_number>, where bucket_number starts from 1.\n",
    "\n",
    "* Currently, our model uses the ST_GeogPoint function to derive the pickup and dropoff feature.  In this lab, we use the BUCKETIZE function to create the pickup and dropoff feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-VzlYCG1ytU"
   },
   "source": [
    "Next, apply the BUCKETIZE function to model_7 and run the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bE3ZRGV21yta",
    "outputId": "83952ef3-62a2-4719-e647-5e0285424082"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL\n",
    "  feat_eng.model_7 OPTIONS (model_type='linear_reg',\n",
    "    input_label_cols=['fare_amount']) AS\n",
    "SELECT\n",
    "  fare_amount,\n",
    "  passengers,\n",
    "  ST_Distance(ST_GeogPoint(pickuplon,\n",
    "      pickuplat),\n",
    "    ST_GeogPoint(dropofflon,\n",
    "      dropofflat)) AS euclidean,\n",
    "  ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS dayofweek,\n",
    "      CAST(EXTRACT(HOUR\n",
    "        FROM\n",
    "          pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "\n",
    "#TODO 4 -- Your code here.\n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "FROM\n",
    "  `feat_eng.feateng_training_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AVPXGKZ374v7"
   },
   "source": [
    "Next, we evaluate model_7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRZc6S101ytc",
    "outputId": "237ba0f9-c2f7-4351-b2ce-879b9b301c3c"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *,\n",
    "  SQRT(loss) AS rmse\n",
    "FROM\n",
    "  ML.TRAINING_INFO(MODEL feat_eng.model_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-X1oUFpm1yte",
    "outputId": "ef90ec44-eb0f-4201-fbb5-9e29a2c240d3"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXpHTWhv1ytg",
    "outputId": "f15ca9f6-b5aa-4084-ce9f-3b7579f7c7eb"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.model_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8PojyIe1ytk"
   },
   "source": [
    "### Final Model:  Apply the TRANSFORM clause and L2 Regularization\n",
    "\n",
    "Before we perform our prediction, we should encapsulate the entire feature set in a TRANSFORM clause.  BigQuery ML now supports defining data transformations during model creation, which will be automatically applied during prediction and evaluation. This is done through the TRANSFORM clause in the existing CREATE MODEL statement. By using the TRANSFORM clause, user specified transforms during training will be automatically applied during model serving (prediction, evaluation, etc.) \n",
    "\n",
    "In our case, we are using the TRANSFORM clause to separate out the raw input data from the TRANSFORMED features.  The input columns of the TRANSFORM clause is the query_expr (AS SELECT part).  The output columns of TRANSFORM from select_list are used in training. These transformed columns are post-processed with standardization for numerics and one-hot encoding for categorical variables by default. \n",
    "\n",
    "The advantage of encapsulating features in the TRANSFORM clause is the client code doing the PREDICT doesn't change, e.g. our model improvement is transparent to client code. Note that the TRANSFORM clause MUST be placed after the CREATE statement.\n",
    "\n",
    "##### [L2 Regularization](https://developers.google.com/machine-learning/glossary/#L2_regularization) \n",
    "Sometimes, the training RMSE is quite reasonable, but the evaluation RMSE illustrate more error. Given the severity of the delta between the EVALUATION RMSE and the TRAINING RMSE, it may be an indication of overfitting. When we do feature crosses, we run into the risk of overfitting (for example, when a particular day-hour combo doesn't have enough taxi rides).\n",
    "\n",
    "Overfitting is a phenomenon that occurs when a machine learning or statistics model is tailored to a particular dataset and is unable to generalize to other datasets. This usually happens in complex models, like deep neural networks.  Regularization is a process of introducing additional information in order to prevent overfitting.\n",
    "\n",
    "Therefore, we will apply L2 Regularization to the final model.  As a reminder, a regression model that uses the L1 regularization technique is called Lasso Regression while a regression model that uses the L2 Regularization technique is called Ridge Regression.  The key difference between these two is the penalty term.  Lasso shrinks the less important feature’s coefficient to zero, thus removing some features altogether.  Ridge regression adds “squared magnitude” of coefficient as a penalty term to the loss function.\n",
    "\n",
    "In other words, L1 limits the size of the coefficients. L1 can yield sparse models (i.e. models with few coefficients); Some coefficients can become zero and eliminated. \n",
    "\n",
    "L2 regularization adds an L2 penalty equal to the square of the magnitude of coefficients. L2 will not yield sparse models and all coefficients are shrunk by the same factor (none are eliminated). \n",
    "\n",
    "The regularization terms are ‘constraints’ by which an optimization algorithm must ‘adhere to’ when minimizing the loss function, apart from having to minimize the error between the true y and the predicted ŷ.  This in turn reduces model complexity, making our model simpler. A simpler model can reduce the chances of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZuZPtES1ytl"
   },
   "source": [
    "Now, replace the blanks with the correct syntax to apply the TRANSFORM clause and L2 Regularization to the final model. Delete the \"TODO 5\" when you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKf_4I771ytn",
    "outputId": "c3ed43f9-59de-44e0-b4bb-a35e3e34874e"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "CREATE OR REPLACE MODEL\n",
    "  feat_eng.final_model \n",
    "    TODO 5:_________ (fare_amount,\n",
    "    #SQRT( (pickuplon-dropofflon)*(pickuplon-dropofflon) + (pickuplat-dropofflat)*(pickuplat-dropofflat) ) AS euclidean,\n",
    "    ST_Distance(ST_GeogPoint(pickuplon,\n",
    "        pickuplat),\n",
    "      ST_GeogPoint(dropofflon,\n",
    "        dropofflat)) AS euclidean,\n",
    "    ML.FEATURE_CROSS(STRUCT(CAST(EXTRACT(DAYOFWEEK\n",
    "          FROM\n",
    "            pickup_datetime) AS STRING) AS dayofweek,\n",
    "        CAST(EXTRACT(HOUR\n",
    "          FROM\n",
    "            pickup_datetime) AS STRING) AS hourofday)) AS day_hr,\n",
    "    CONCAT( ML.BUCKETIZE(pickuplon,\n",
    "        GENERATE_ARRAY(-78, -70, 0.01)), ML.BUCKETIZE(pickuplat,\n",
    "        GENERATE_ARRAY(37, 45, 0.01)), ML.BUCKETIZE(dropofflon,\n",
    "        GENERATE_ARRAY(-78, -70, 0.01)), ML.BUCKETIZE(dropofflat,\n",
    "        GENERATE_ARRAY(37, 45, 0.01)) ) AS pickup_and_dropoff ) OPTIONS(input_label_cols=['fare_amount'],\n",
    "    model_type='linear_reg',\n",
    "    TODO 5:_________) AS\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  feat_eng.feateng_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Sb4U38_1yto"
   },
   "source": [
    "Next, we evaluate the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqUNost_1ytq",
    "outputId": "998edad7-c023-4afb-a820-633a5ed30124"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *,\n",
    "  SQRT(loss) AS rmse\n",
    "FROM\n",
    "  ML.TRAINING_INFO(MODEL feat_eng.final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdQnFs8q1yts",
    "outputId": "ba9df792-bb74-49d1-a284-7efdcc8b6ba7"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhaD7-rI1ytu",
    "outputId": "ef5c5b2c-2451-40eb-ee96-81b48de1542f"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  SQRT(mean_squared_error) AS rmse\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL feat_eng.final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5cnCLq72Uu8"
   },
   "source": [
    "### Predictive Model\n",
    "\n",
    "\n",
    "Now that you have evaluated your model, the next step is to use it to predict an outcome. You use your model to predict the taxifare amount. \n",
    "The ML.PREDICT function is used to predict results using your model: feat_eng.final_model.  \n",
    "\n",
    "Since this is a regression model (predicting a continuous numerical value), the best way to see how it performed is to evaluate the difference between the value predicted by the model and the benchmark score. We can do this with an ML.PREDICT query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, replace the blanks with the correct syntax to apply the ML.PREDICT function. Delete the \"TODO 6\" when you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ohaHCFW204X"
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  TODO 6:_______\n",
    "        (_________________,\n",
    "    (\n",
    "    SELECT\n",
    "      -73.982683 AS pickuplon,\n",
    "      40.742104 AS pickuplat,\n",
    "      -73.983766 AS dropofflon,\n",
    "      40.755174 AS dropofflat,\n",
    "      3.0 AS passengers,\n",
    "      TIMESTAMP('2019-06-03 04:21:29.769443 UTC') AS pickup_datetime ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQeF100u3U3Z"
   },
   "source": [
    "### Lab Summary: \n",
    "Our ML problem:  Develop a model to predict taxi fare based on distance -- from one point to another in New York City. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bW4twucJ3c37"
   },
   "source": [
    "#### OPTIONAL Exercise: Create a RMSE summary table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBJGVTQJ2Cp3"
   },
   "source": [
    "**Markdown table generator**:  http://www.tablesgenerator.com/markdown_tables\n",
    "Create a RMSE summary table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution Table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model       | Taxi Fare | Description                           |\n",
    "|-------------|-----------|---------------------------------------|\n",
    "| model_4     | 9.65      | --Feature cross categorical features  |\n",
    "| model_5     | 5.58      | --Create a Euclidian feature column   |\n",
    "| model_6     | 5.90      | --Feature cross Geo-location features |\n",
    "| model_7     | 6.23      | --Apply the TRANSFORM Clause          |\n",
    "| final_model | 5.39      | --Apply L2 Regularization             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAsY468W4BuK"
   },
   "source": [
    "**RUN** the cell to visualize a RMSE bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRNfpJvW3V2n"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "x = ['m4', 'm5', 'm6','m7', 'final']\n",
    "RMSE = [9.65,5.58,5.90,6.23,5.39]\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "plt.bar(x_pos, RMSE, color='green')\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE Model Summary\")\n",
    "\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bqml_adv_feat_eng.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
