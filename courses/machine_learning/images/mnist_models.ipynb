{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow on Cloud ML Engine\n",
    "\n",
    "This notebook demonstrates how to implement different image models on MNIST using the [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras). It will compare the performance between linear, dense, dropout, and cnn models. Finally, it will show how to deploy the model to Google Cloud's [AI Platforms](https://cloud.google.com/ai-platform/) for training and prediction.\n",
    "\n",
    "First things first. Configure the parameters below to match your own Google Cloud project details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "PROJECT = \"your-project-id-here\" # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = \"your-bucket-id-here\" # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = \"us-central1\" # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"IMAGE_URI\"] = \"gcr.io/\" + PROJECT + \"/mnist_trainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dynamic model\n",
    "\n",
    "In the previous notebook <a href=\"mnist_linear.ipynb\">mnist_linear.ipynb</a> we ran our code directly from the notebook. In order to run it on the AI Platform, it needs to be packaged as a python module.\n",
    "\n",
    "The boilerplate structure for this module has already been set up in the folder `mnist_models`. The module lives in the sub-folder `trainer` and is designated as a python package with the empty `__init__.py` (`mnist_models/trainer/__init__.py`) file. It still needs the model and a trainer to run it, so let's make them.\n",
    "\n",
    "Let's start with the trainer file fist. This file parses command line arguments to feed into model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist_trainer/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_trainer/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from . import model\n",
    "\n",
    "\n",
    "def _parse_arguments(argv):\n",
    "    \"\"\"Parses command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--model_type',\n",
    "        help='Which model type to use',\n",
    "        type=str, default='linear')\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        help='The number of epochs to train',\n",
    "        type=int, default=10)\n",
    "    parser.add_argument(\n",
    "        '--steps_per_epoch',\n",
    "        help='The number of steps per epoch to train',\n",
    "        type=int, default=100)\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help='Directory where to save the given model',\n",
    "        type=str, default='mnist_models/')\n",
    "    return parser.parse_known_args(argv)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Parses command line arguments and kicks off model training.\"\"\"\n",
    "    args = _parse_arguments(sys.argv[1:])[0]\n",
    "    \n",
    "    # Configure path for hyperparameter tuning.\n",
    "    trial_id = json.loads(\n",
    "        os.environ.get('TF_CONFIG', '{}')).get('task', {}).get('trial', '')\n",
    "    output_path = args.job_dir if not trial_id else args.job_dir + '/'\n",
    "    \n",
    "    model_layers = model.get_layers(args.model_type)\n",
    "    keras_model, _ = model.create_and_train_model(\n",
    "        model_layers, args.epochs, args.steps_per_epoch, args.job_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets group non-model functions into a util file to keep the model file simple. We'll copy over the `scale` and `load_dataset` functions from the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist_trainer/trainer/util.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_trainer/trainer/util.py\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def scale(image, label):\n",
    "    \"\"\"Scales images from a 0-255 int range to a 0-1 float range\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    data, training=True, buffer_size=5000, batch_size=100, nclassses=10):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, nclassses)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's code the models! The [tf.keras API](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras) accepts an array of [layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) into a [model object](https://www.tensorflow.org/api_docs/python/tf/keras/Model), so we can create a dictionary of layers based on the different model types we want to use. The below file has two functions: `get_layers` and `create_and_train_model`. We will build the structure of our model in `get_layers`. Last but not least, we'll copy over the training code from the previoud lab into `create_and_train_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist_trainer/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_trainer/trainer/model.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Softmax)\n",
    "\n",
    "from . import util\n",
    "\n",
    "\n",
    "# Image Variables\n",
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "\n",
    "\n",
    "def get_layers(\n",
    "        model_type,\n",
    "        nclasses=10,\n",
    "        hidden_layer_1_nuerons=400,\n",
    "        hidden_layer_2_nuerons=100,\n",
    "        dropout_rate=0.25,\n",
    "        num_filters_1=64,\n",
    "        kernel_size_1=3,\n",
    "        pooling_size_1=2,\n",
    "        num_filters_2=32,\n",
    "        kernel_size_2=3,\n",
    "        pooling_size_2=2):\n",
    "    \"\"\"Constructs layers for a keras model based on a dict of model types.\"\"\"\n",
    "    model_layers = {\n",
    "        'linear': [\n",
    "            Flatten(),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_nuerons, activation='relu'),\n",
    "            Dense(hidden_layer_2_nuerons, activation='relu'),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'dnn_dropout': [\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_nuerons, activation='relu'),\n",
    "            Dense(hidden_layer_2_nuerons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ],\n",
    "        'cnn': [\n",
    "            Conv2D(num_filters_1, kernel_size=kernel_size_1,\n",
    "                   activation='relu', input_shape=(WIDTH, HEIGHT, 1)),\n",
    "            MaxPooling2D(pooling_size_1),\n",
    "            Conv2D(num_filters_2, kernel_size=kernel_size_2,\n",
    "                   activation='relu'),\n",
    "            MaxPooling2D(pooling_size_2),\n",
    "            Flatten(),\n",
    "            Dense(hidden_layer_1_nuerons, activation='relu'),\n",
    "            Dense(hidden_layer_2_nuerons, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(nclasses),\n",
    "            Softmax()\n",
    "        ]\n",
    "    }\n",
    "    return model_layers[model_type]\n",
    "\n",
    "\n",
    "def create_and_train_model(layers, num_epochs, steps_per_epoch, output_dir):\n",
    "    \"\"\"Compiles keras model and loads data into it for training.\"\"\"\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    train_data = util.load_dataset(mnist)\n",
    "    validation_data = util.load_dataset(mnist, training=False)\n",
    "\n",
    "    callbacks = []\n",
    "    if output_dir:\n",
    "        tensorboard_callback = TensorBoard(log_dir=output_dir)\n",
    "        callbacks = [tensorboard_callback]\n",
    "\n",
    "    model = Sequential(layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=validation_data,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "    \n",
    "    if output_dir:\n",
    "        export_path = os.path.join(output_dir, 'keras_export')\n",
    "        model.save(export_path, save_format='tf')\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Training\n",
    "\n",
    "With everything set up, let's run locally to test the code. First, some of the previous tests have been copied over into a testing script `mnist_models/trainer/test.py` to make sure the model still passes our previous checks. On `line 34`, you can specify which model types you would like to check. `line 37` and `line 38` has the number of epochs and steps per epoch respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-04 00:43:06.053810: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-10-04 00:43:06.074908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-10-04 00:43:06.075291: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db5522c3a0 executing computations on platform Host. Devices:\n",
      "2019-10-04 00:43:06.075321: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      ".2019-10-04 00:43:16.467139: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 1250 of 5000\n",
      "2019-10-04 00:43:20.909917: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      ".\n",
      "*** Building model for linear ***\n",
      "\n",
      "Epoch 1/10\n",
      "2019-10-04 00:43:31.315691: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 1261 of 5000\n",
      "2019-10-04 00:43:35.685881: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1004 00:43:35.825198 140009993455360 deprecation.py:323] From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2019-10-04 00:43:36.107165: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "100/100 - 16s - loss: 1.3206 - accuracy: 0.5008 - val_loss: 0.7875 - val_accuracy: 0.8316\n",
      "Epoch 2/10\n",
      "100/100 - 1s - loss: 0.6634 - accuracy: 0.8364 - val_loss: 0.5548 - val_accuracy: 0.8691\n",
      "Epoch 3/10\n",
      "100/100 - 1s - loss: 0.5452 - accuracy: 0.8611 - val_loss: 0.4652 - val_accuracy: 0.8879\n",
      "Epoch 4/10\n",
      "100/100 - 1s - loss: 0.4601 - accuracy: 0.8891 - val_loss: 0.4193 - val_accuracy: 0.8954\n",
      "Epoch 5/10\n",
      "100/100 - 1s - loss: 0.4126 - accuracy: 0.8895 - val_loss: 0.3941 - val_accuracy: 0.8987\n",
      "Epoch 6/10\n",
      "100/100 - 1s - loss: 0.3940 - accuracy: 0.8999 - val_loss: 0.3681 - val_accuracy: 0.9050\n",
      "Epoch 7/10\n",
      "100/100 - 1s - loss: 0.3703 - accuracy: 0.9053 - val_loss: 0.3509 - val_accuracy: 0.9083\n",
      "Epoch 8/10\n",
      "100/100 - 1s - loss: 0.3547 - accuracy: 0.8987 - val_loss: 0.3408 - val_accuracy: 0.9087\n",
      "Epoch 9/10\n",
      "100/100 - 1s - loss: 0.3552 - accuracy: 0.9087 - val_loss: 0.3320 - val_accuracy: 0.9093\n",
      "Epoch 10/10\n",
      "100/100 - 1s - loss: 0.3552 - accuracy: 0.8915 - val_loss: 0.3231 - val_accuracy: 0.9141\n",
      "\n",
      "*** Building model for dnn ***\n",
      "\n",
      "Epoch 1/10\n",
      "2019-10-04 00:44:01.160800: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 1299 of 5000\n",
      "2019-10-04 00:44:05.160872: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      "100/100 - 16s - loss: 0.5881 - accuracy: 0.7084 - val_loss: 0.2815 - val_accuracy: 0.9186\n",
      "Epoch 2/10\n",
      "100/100 - 2s - loss: 0.2493 - accuracy: 0.9181 - val_loss: 0.2059 - val_accuracy: 0.9388\n",
      "Epoch 3/10\n",
      "100/100 - 2s - loss: 0.2123 - accuracy: 0.9410 - val_loss: 0.1723 - val_accuracy: 0.9481\n",
      "Epoch 4/10\n",
      "100/100 - 2s - loss: 0.1681 - accuracy: 0.9475 - val_loss: 0.1462 - val_accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "100/100 - 2s - loss: 0.1464 - accuracy: 0.9585 - val_loss: 0.1290 - val_accuracy: 0.9615\n",
      "Epoch 6/10\n",
      "100/100 - 2s - loss: 0.1418 - accuracy: 0.9554 - val_loss: 0.1338 - val_accuracy: 0.9586\n",
      "Epoch 7/10\n",
      "100/100 - 2s - loss: 0.1042 - accuracy: 0.9663 - val_loss: 0.1136 - val_accuracy: 0.9663\n",
      "Epoch 8/10\n",
      "100/100 - 2s - loss: 0.1032 - accuracy: 0.9721 - val_loss: 0.1016 - val_accuracy: 0.9694\n",
      "Epoch 9/10\n",
      "100/100 - 2s - loss: 0.0939 - accuracy: 0.9752 - val_loss: 0.1084 - val_accuracy: 0.9668\n",
      "Epoch 10/10\n",
      "100/100 - 2s - loss: 0.0891 - accuracy: 0.9708 - val_loss: 0.0961 - val_accuracy: 0.9704\n",
      "\n",
      "*** Building model for dnn_dropout ***\n",
      "\n",
      "Epoch 1/10\n",
      "2019-10-04 00:44:33.073677: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 1314 of 5000\n",
      "2019-10-04 00:44:36.818583: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      "100/100 - 16s - loss: 0.6559 - accuracy: 0.6603 - val_loss: 0.2798 - val_accuracy: 0.9181\n",
      "Epoch 2/10\n",
      "100/100 - 2s - loss: 0.3066 - accuracy: 0.9084 - val_loss: 0.2054 - val_accuracy: 0.9377\n",
      "Epoch 3/10\n",
      "100/100 - 2s - loss: 0.2354 - accuracy: 0.9247 - val_loss: 0.1814 - val_accuracy: 0.9441\n",
      "Epoch 4/10\n",
      "100/100 - 2s - loss: 0.1997 - accuracy: 0.9398 - val_loss: 0.1580 - val_accuracy: 0.9527\n",
      "Epoch 5/10\n",
      "100/100 - 2s - loss: 0.1914 - accuracy: 0.9433 - val_loss: 0.1408 - val_accuracy: 0.9552\n",
      "Epoch 6/10\n",
      "100/100 - 2s - loss: 0.1658 - accuracy: 0.9440 - val_loss: 0.1165 - val_accuracy: 0.9640\n",
      "Epoch 7/10\n",
      "100/100 - 2s - loss: 0.1210 - accuracy: 0.9637 - val_loss: 0.1047 - val_accuracy: 0.9660\n",
      "Epoch 8/10\n",
      "100/100 - 2s - loss: 0.1282 - accuracy: 0.9599 - val_loss: 0.1093 - val_accuracy: 0.9675\n",
      "Epoch 9/10\n",
      "100/100 - 2s - loss: 0.1111 - accuracy: 0.9686 - val_loss: 0.1014 - val_accuracy: 0.9699\n",
      "Epoch 10/10\n",
      "100/100 - 2s - loss: 0.1234 - accuracy: 0.9633 - val_loss: 0.1025 - val_accuracy: 0.9703\n",
      "\n",
      "*** Building model for cnn ***\n",
      "\n",
      "Epoch 1/10\n",
      "2019-10-04 00:45:04.857858: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 1320 of 5000\n",
      "2019-10-04 00:45:08.518636: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      "100/100 - 22s - loss: 0.6741 - accuracy: 0.7846 - val_loss: 0.1842 - val_accuracy: 0.9468\n",
      "Epoch 2/10\n",
      "100/100 - 7s - loss: 0.1873 - accuracy: 0.9412 - val_loss: 0.1192 - val_accuracy: 0.9623\n",
      "Epoch 3/10\n",
      "100/100 - 7s - loss: 0.1422 - accuracy: 0.9569 - val_loss: 0.1056 - val_accuracy: 0.9669\n",
      "Epoch 4/10\n",
      "100/100 - 8s - loss: 0.1004 - accuracy: 0.9695 - val_loss: 0.0714 - val_accuracy: 0.9778\n",
      "Epoch 5/10\n",
      "100/100 - 8s - loss: 0.0896 - accuracy: 0.9716 - val_loss: 0.0575 - val_accuracy: 0.9817\n",
      "Epoch 6/10\n",
      "100/100 - 8s - loss: 0.0860 - accuracy: 0.9751 - val_loss: 0.0495 - val_accuracy: 0.9853\n",
      "Epoch 7/10\n",
      "100/100 - 8s - loss: 0.0603 - accuracy: 0.9817 - val_loss: 0.0516 - val_accuracy: 0.9839\n",
      "Epoch 8/10\n",
      "100/100 - 8s - loss: 0.0605 - accuracy: 0.9812 - val_loss: 0.0407 - val_accuracy: 0.9866\n",
      "Epoch 9/10\n",
      "100/100 - 8s - loss: 0.0609 - accuracy: 0.9813 - val_loss: 0.0464 - val_accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "100/100 - 8s - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.0548 - val_accuracy: 0.9824\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 201.777s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mnist_trainer.trainer.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that our models are working as expected, let's run it on the [Google Cloud Ai Platform](https://cloud.google.com/ml-engine/docs/). We can run it locally first using the [gcloud ai-platform local train](https://cloud.google.com/sdk/gcloud/reference/ai-platform/local/train) command line command.\n",
    "\n",
    "The below cell transfers some of our variables to the command line as well as create a job directory including a timestamp. This is where our model and tensorboard data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "model_type = 'cnn'\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"mnist_{}_{}/\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below runs the local version of the Google Cloud AI Platform. The epochs and steps_per_epoch flag can be changed to run for longer or shorther, as defined in our `mnist_models/trainer/task.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 - 22s - loss: 1.0108 - accuracy: 0.6782 - val_loss: 0.3238 - val_accuracy: 0.9020\n",
      "Epoch 2/5\n",
      "50/50 - 5s - loss: 0.3175 - accuracy: 0.9022 - val_loss: 0.1846 - val_accuracy: 0.9428\n",
      "Epoch 3/5\n",
      "50/50 - 5s - loss: 0.1978 - accuracy: 0.9402 - val_loss: 0.1242 - val_accuracy: 0.9618\n",
      "Epoch 4/5\n",
      "50/50 - 5s - loss: 0.1660 - accuracy: 0.9520 - val_loss: 0.0917 - val_accuracy: 0.9706\n",
      "Epoch 5/5\n",
      "50/50 - 5s - loss: 0.1744 - accuracy: 0.9486 - val_loss: 0.0981 - val_accuracy: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-04 00:46:30.294502: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-10-04 00:46:30.302342: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-10-04 00:46:30.302772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557fc39071f0 executing computations on platform Host. Devices:\n",
      "2019-10-04 00:46:30.302818: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-10-04 00:46:40.574234: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 1258 of 5000\n",
      "2019-10-04 00:46:46.885633: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1004 00:46:46.946861 140203501336000 deprecation.py:323] From /home/jupyter/.local/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2019-10-04 00:46:47.634576: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2019-10-04 00:46:47.741547: I tensorflow/core/profiler/lib/profiler_session.cc:174] Profiler session started.\n",
      "2019-10-04 00:47:11.827743: W tensorflow/python/util/util.cc:280] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=${PWD}/mnist_trainer/trainer \\\n",
    "    --job-dir=${PWD}/$JOB_DIR \\\n",
    "    -- \\\n",
    "    --epochs=5 \\\n",
    "    --steps_per_epoch=50 \\\n",
    "    --model_type=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how the model did in tensorboard and confirm that it's good to go before kicking it off to train on the cloud. If running on a Deep Learning VM, open the folder `courses/machine_learning/images/mnist_linear`. Then, go to File > New Launcher. Click on Tensorboard under \"Other\".\n",
    "\n",
    "If runnining locally, the following command can be run in a terminal:\n",
    "\n",
    "`tensorboard --logdir=<path-to-data-directory>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the cloud\n",
    "\n",
    "Since we're using an unreleased version of TensorFlow on AI Platform, we can instead use a [Deep Learning Container](https://cloud.google.com/ai-platform/deep-learning-containers/docs/overview) in order to take advantage of libraries and applications not normally packaged with AI Platform. Below is a simple [Dockerlife](https://docs.docker.com/engine/reference/builder/) which copies our code ro be used in a TF2 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist_trainer/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist_trainer/Dockerfile\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu\n",
    "COPY trainer /trainer\n",
    "ENTRYPOINT [\"python3\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below command builds the image and ships it off to Google Cloud so it can be used for AI Platform. When built, it will show up [here](https://pantheon.corp.google.com/gcr) with the name `mnist_trainer`. This only needs to be done once, even if the code here locally needs to be restarted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 19 file(s) totalling 29.4 KiB before compression.\n",
      "Uploading tarball of [mnist_trainer/] to [gs://ddetering-experimental_cloudbuild/source/1570150213.32-64f00497af4f434b9a931d3268f3cda4.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/ddetering-experimental/builds/74180d69-8cc4-44ba-8d3b-f1738ab4c60d].\n",
      "Logs are available at [https://console.cloud.google.com/gcr/builds/74180d69-8cc4-44ba-8d3b-f1738ab4c60d?project=894743430090].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"74180d69-8cc4-44ba-8d3b-f1738ab4c60d\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://ddetering-experimental_cloudbuild/source/1570150213.32-64f00497af4f434b9a931d3268f3cda4.tgz#1570150213892391\n",
      "Copying gs://ddetering-experimental_cloudbuild/source/1570150213.32-64f00497af4f434b9a931d3268f3cda4.tgz#1570150213892391...\n",
      "/ [1 files][  8.1 KiB/  8.1 KiB]                                                \n",
      "Operation completed over 1 objects/8.1 KiB.                                      \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  48.13kB\n",
      "Step 1/3 : FROM gcr.io/deeplearning-platform-release/tf2-cpu\n",
      "latest: Pulling from deeplearning-platform-release/tf2-cpu\n",
      "35c102085707: Pulling fs layer\n",
      "251f5509d51d: Pulling fs layer\n",
      "8e829fe70a46: Pulling fs layer\n",
      "6001e1789921: Pulling fs layer\n",
      "64aa7508993b: Pulling fs layer\n",
      "75ff22edc694: Pulling fs layer\n",
      "2824001707aa: Pulling fs layer\n",
      "6e72a0346b55: Pulling fs layer\n",
      "06fde9d517f9: Pulling fs layer\n",
      "7eda0768b66e: Pulling fs layer\n",
      "e0112d80e90f: Pulling fs layer\n",
      "2c94144fd154: Pulling fs layer\n",
      "c4b041c3f63b: Pulling fs layer\n",
      "bd60eb9c51a2: Pulling fs layer\n",
      "06fab61e625d: Pulling fs layer\n",
      "42ec45994b02: Pulling fs layer\n",
      "e720cb581e90: Pulling fs layer\n",
      "bbf43f398ed6: Pulling fs layer\n",
      "23256ae355db: Pulling fs layer\n",
      "6001e1789921: Waiting\n",
      "64aa7508993b: Waiting\n",
      "75ff22edc694: Waiting\n",
      "2824001707aa: Waiting\n",
      "6e72a0346b55: Waiting\n",
      "06fde9d517f9: Waiting\n",
      "7eda0768b66e: Waiting\n",
      "e0112d80e90f: Waiting\n",
      "2c94144fd154: Waiting\n",
      "c4b041c3f63b: Waiting\n",
      "bd60eb9c51a2: Waiting\n",
      "06fab61e625d: Waiting\n",
      "42ec45994b02: Waiting\n",
      "e720cb581e90: Waiting\n",
      "bbf43f398ed6: Waiting\n",
      "23256ae355db: Waiting\n",
      "251f5509d51d: Verifying Checksum\n",
      "251f5509d51d: Download complete\n",
      "8e829fe70a46: Verifying Checksum\n",
      "8e829fe70a46: Download complete\n",
      "6001e1789921: Verifying Checksum\n",
      "6001e1789921: Download complete\n",
      "35c102085707: Verifying Checksum\n",
      "35c102085707: Download complete\n",
      "2824001707aa: Verifying Checksum\n",
      "2824001707aa: Download complete\n",
      "75ff22edc694: Verifying Checksum\n",
      "75ff22edc694: Download complete\n",
      "06fde9d517f9: Verifying Checksum\n",
      "06fde9d517f9: Download complete\n",
      "7eda0768b66e: Verifying Checksum\n",
      "7eda0768b66e: Download complete\n",
      "e0112d80e90f: Verifying Checksum\n",
      "e0112d80e90f: Download complete\n",
      "2c94144fd154: Verifying Checksum\n",
      "2c94144fd154: Download complete\n",
      "c4b041c3f63b: Verifying Checksum\n",
      "c4b041c3f63b: Download complete\n",
      "bd60eb9c51a2: Verifying Checksum\n",
      "bd60eb9c51a2: Download complete\n",
      "06fab61e625d: Verifying Checksum\n",
      "06fab61e625d: Download complete\n",
      "42ec45994b02: Verifying Checksum\n",
      "42ec45994b02: Download complete\n",
      "64aa7508993b: Verifying Checksum\n",
      "64aa7508993b: Download complete\n",
      "bbf43f398ed6: Verifying Checksum\n",
      "bbf43f398ed6: Download complete\n",
      "23256ae355db: Verifying Checksum\n",
      "23256ae355db: Download complete\n",
      "e720cb581e90: Verifying Checksum\n",
      "e720cb581e90: Download complete\n",
      "35c102085707: Pull complete\n",
      "251f5509d51d: Pull complete\n",
      "8e829fe70a46: Pull complete\n",
      "6001e1789921: Pull complete\n",
      "6e72a0346b55: Verifying Checksum\n",
      "6e72a0346b55: Download complete\n",
      "64aa7508993b: Pull complete\n",
      "75ff22edc694: Pull complete\n",
      "2824001707aa: Pull complete\n",
      "6e72a0346b55: Pull complete\n",
      "06fde9d517f9: Pull complete\n",
      "7eda0768b66e: Pull complete\n",
      "e0112d80e90f: Pull complete\n",
      "2c94144fd154: Pull complete\n",
      "c4b041c3f63b: Pull complete\n",
      "bd60eb9c51a2: Pull complete\n",
      "06fab61e625d: Pull complete\n",
      "42ec45994b02: Pull complete\n",
      "e720cb581e90: Pull complete\n",
      "bbf43f398ed6: Pull complete\n",
      "23256ae355db: Pull complete\n",
      "Digest: sha256:b80b858f464e72a5c6d4a3c79ccc44407eeedb1e553b2976f4e7cae1d7fd93cd\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu:latest\n",
      " ---> bed936671274\n",
      "Step 2/3 : COPY trainer /trainer\n",
      " ---> 39af2f32695e\n",
      "Step 3/3 : ENTRYPOINT [\"python3\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in 890e1105baf3\n",
      "Removing intermediate container 890e1105baf3\n",
      " ---> 210802c0df83\n",
      "Successfully built 210802c0df83\n",
      "Successfully tagged gcr.io/ddetering-experimental/mnist_trainer:latest\n",
      "PUSH\n",
      "Pushing gcr.io/ddetering-experimental/mnist_trainer\n",
      "The push refers to repository [gcr.io/ddetering-experimental/mnist_trainer]\n",
      "9a517165fb96: Preparing\n",
      "bf90a9083c07: Preparing\n",
      "11d81998383e: Preparing\n",
      "95d20553f9d8: Preparing\n",
      "db39d1d921f4: Preparing\n",
      "30a800c3bce3: Preparing\n",
      "b4e8d60ebd43: Preparing\n",
      "e1331da2fed4: Preparing\n",
      "47b98e0067a4: Preparing\n",
      "1540993b0bb8: Preparing\n",
      "aeb8ac7a4b4c: Preparing\n",
      "3502212822b5: Preparing\n",
      "a792cec8f1b3: Preparing\n",
      "fd6e4fea6397: Preparing\n",
      "e661f78768b4: Preparing\n",
      "cb4cde3af37a: Preparing\n",
      "122be11ab4a2: Preparing\n",
      "7beb13bce073: Preparing\n",
      "f7eae43028b3: Preparing\n",
      "6cebf3abed5f: Preparing\n",
      "30a800c3bce3: Waiting\n",
      "b4e8d60ebd43: Waiting\n",
      "e1331da2fed4: Waiting\n",
      "47b98e0067a4: Waiting\n",
      "1540993b0bb8: Waiting\n",
      "aeb8ac7a4b4c: Waiting\n",
      "3502212822b5: Waiting\n",
      "a792cec8f1b3: Waiting\n",
      "fd6e4fea6397: Waiting\n",
      "e661f78768b4: Waiting\n",
      "cb4cde3af37a: Waiting\n",
      "122be11ab4a2: Waiting\n",
      "7beb13bce073: Waiting\n",
      "f7eae43028b3: Waiting\n",
      "6cebf3abed5f: Waiting\n",
      "95d20553f9d8: Layer already exists\n",
      "11d81998383e: Layer already exists\n",
      "db39d1d921f4: Layer already exists\n",
      "bf90a9083c07: Layer already exists\n",
      "30a800c3bce3: Layer already exists\n",
      "b4e8d60ebd43: Layer already exists\n",
      "e1331da2fed4: Layer already exists\n",
      "47b98e0067a4: Layer already exists\n",
      "1540993b0bb8: Layer already exists\n",
      "aeb8ac7a4b4c: Layer already exists\n",
      "3502212822b5: Layer already exists\n",
      "a792cec8f1b3: Layer already exists\n",
      "fd6e4fea6397: Layer already exists\n",
      "e661f78768b4: Layer already exists\n",
      "cb4cde3af37a: Layer already exists\n",
      "122be11ab4a2: Layer already exists\n",
      "7beb13bce073: Layer already exists\n",
      "f7eae43028b3: Layer already exists\n",
      "6cebf3abed5f: Layer already exists\n",
      "9a517165fb96: Pushed\n",
      "latest: digest: sha256:77c5fb3d6bc46a2aca2aeb1b10b2c13d0ab99d25438a0e3484e65ddf50808976 size: 4501\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                            IMAGES                                                 STATUS\n",
      "74180d69-8cc4-44ba-8d3b-f1738ab4c60d  2019-10-04T00:50:14+00:00  3M17S     gs://ddetering-experimental_cloudbuild/source/1570150213.32-64f00497af4f434b9a931d3268f3cda4.tgz  gcr.io/ddetering-experimental/mnist_trainer (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $IMAGE_URI mnist_trainer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can kickoff the [AI Platform training job](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training). We can pass in our docker image using the `master-image-uri` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "model_type = 'cnn'\n",
    "\n",
    "os.environ[\"MODEL_TYPE\"] = model_type\n",
    "os.environ[\"JOB_DIR\"] = \"gs://{}/mnist_{}_{}/\".format(\n",
    "    BUCKET, model_type, current_time)\n",
    "os.environ[\"JOB_NAME\"] = \"mnist_{}_{}\".format(\n",
    "    model_type, current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ddetering-experimental/mnist_cnn_191004_005334/ us-central1 mnist_cnn_191004_005334\n",
      "jobId: mnist_cnn_191004_005334\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [mnist_cnn_191004_005334] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe mnist_cnn_191004_005334\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs mnist_cnn_191004_005334\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $JOB_DIR $REGION $JOB_NAME\n",
    "gcloud beta ai-platform jobs submit training $JOB_NAME \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --region=$REGION \\\n",
    "    --master-image-uri=$IMAGE_URI \\\n",
    "    --scale-tier=BASIC_GPU \\\n",
    "    --job-dir=$JOB_DIR \\\n",
    "    -- \\\n",
    "    --model_type=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't wait to see the results? Copy the line above starting with `tensorboard --logdir` into the [Google Cloud Shell](https://console.cloud.google.com/home/dashboard?cloudshell=true&_ga=2.47007073.-710997367.1570027031) to follow along with TensorBoard. Look at the web previw on port 6006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir gs://ddetering-experimental/mnist_cnn_191004_005334/\n"
     ]
    }
   ],
   "source": [
    "!echo \"tensorboard --logdir $JOB_DIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Once you have a model you're proud of, let's deploy it! All we need to do is give AI Platform the location of the model. Below uses the keras eport path of the previous job, but `blah` can always be changed to a different path.\n",
    "\n",
    "Even though we're using a 1.14 runtime, it's compatable with TF2 exported models. Phew!\n",
    "\n",
    "Uncomment the delete commands below if you are getting an \"already exists error\" and want to deploy a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"mnist\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=${JOB_DIR}keras_export/\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#yes | gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#yes | gcloud ai-platform models delete ${MODEL_NAME}\n",
    "gcloud ai-platform models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "    --model ${MODEL_NAME} \\\n",
    "    --origin ${MODEL_LOCATION} \\\n",
    "    --framework tensorflow \\\n",
    "    --runtime-version=1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, codecs\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist_trainer.trainer import util\n",
    "\n",
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "IMGNO = 12\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "test_image = x_test[IMGNO]\n",
    "\n",
    "jsondata = test_image.reshape(HEIGHT, WIDTH, 1).tolist()\n",
    "json.dump(jsondata, codecs.open(\"test.json\", \"w\", encoding = \"utf-8\"))\n",
    "plt.imshow(test_image.reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can send it to the prediction service. The output will have a 1 in the index of the correspoinding digit it is predicting. Congrats! You've completed the lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOFTMAX_3\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform predict \\\n",
    "    --model=mnist \\\n",
    "    --version=${MODEL_TYPE} \\\n",
    "    --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
